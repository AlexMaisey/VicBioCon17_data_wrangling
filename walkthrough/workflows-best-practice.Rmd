---
title: "Putting it all together: Workflows and Best Practice"
author: "Elise Gould"
date: "18/01/2017"
output: html_document
---

## WHY DOCUMENT YOUR CODE? and How?
Helps people USE your code.

## What should go in your README?
Again, list from: British Ecological Society (2014) A Guide to Data Management in Ecology and Evolution. (ed K. Harrison). British Ecological Society. [online]. Available from: www.britishecologicalsociety.org/publications/journals.

### project level
project aim, objectives, hypotheses
personnel involved throughout the project, including who to contact for questions
details of sponsors
data structure and organisation of files
software used to prepare and read the data
procedures used for data processing, including quality control and versioning, and the dates these were carried out
known problems limiting data use
instructions on how to cite the data
intellectual property rights and other licensing considerations

Elsewhere, perhaps a documentation folder:
data collection methods, details of instrumentation, environmental conditions during collection, copies of collection instructions if applicable
standards used

### data level
This should not go in the readme.... not sold on a gold standard procedure for this yet

- names, lavels, descriptions for variables
- detailed explanation of codes used
- definitions of acronyms or specialist terminology
- reasons for missing values
- derived data created from the raw file, including the code or algorithm used to create them.
- note that much of this documentaiton is embedded in the analysis

### Metadata

- descriptive: fields such as title, author, abstract keywords
- administrative: rights, permissions and data on formatting
- structural: explanations of e.g. tables in the data
- create metadata AS YOU GO, at the same time... your memory is much worse than you perceive it to be.

White, E., Baldridge, E., Brym, Z., Locey, K., McGlinn, D., Supp, S. (2013) Nine simple ways to make it easier to (re)use your data. IEE. 6, 1–10.

Why metadata: "The first key to using data is understanding it. Meta- data is information about the data, including how it was collected, what the units of measurement are, and descriptions of how to best use the data (Michener and Jones 2012). Clear metadata makes it easier to figure out if a dataset is appropriate for a project. It also makes data easier to use by both the original investigators and by other scientists by making it easy to figure out how to work with the data. Without clear metadata, datasets can be overlooked or go unused due to the difficulty of understanding the data (Fraser and Gluck 1999, Zimmerman 2003). Undocumented data also becomes less useful over time as information about the data is gradually lost (Michener et al. 1997)."

WHAT metadata: 

"Metadata can take several forms, including descript- tive file and column names, a written description of the data, images (i.e., maps, photographs), and specially structured information that can be read by computers (either as separate files or part of the data files; i.e., machine readable metadata). Good metadata should provide the following information (Michener et al. 1997, Zimmerman 2003, Strasser et al. 2012): 
- The what, when, where, and how of data collect- ion.
- How to find and access the data.   
- Suggestions on the suitability of the data for ans-wering specific questions.
- Warnings about known problems or inconsist-
encies in the data, e.g., general descriptions of data limitations or a column in a table to indicate the quality of individual data points.
- Information to check that the data are properly
imported, e.g., the number of rows and columns in the dataset and the total sum of numerical columns."

"Writing good metadata does not necessarily require a lot of extra time. The easiest way to develop metadata is to start describing your data during the planning and data collection stages. This will help you stay organized, make it easier to work with your data after it has been collected, and make eventual publication of the data easier."

# notes on licensing

White, E., Baldridge, E., Brym, Z., Locey, K., McGlinn, D., Supp, S. (2013) Nine simple ways to make it easier to (re)use your data. IEE. 6, 1–10.

"Including an explicit license with your data is the best way to let others know exactly what they can and cannot do with the data you shared. Following the Panton Principles http://pantonprinciples.org we recom- mend:
1. Using well established licenses (or waivers) in order to clearly communicate the rights and resp- onsibilities of both the people providing the data and the people using it.
2. Using the most open license (or waiver) possible, because even minor restrictions on data use can have unintended consequences for the reuse of the data (Schofield et al. 2009, Poisot et al. 2013).
The Creative Commons Zero (CC0) public domain dedication places no restrictions on data use and is considered by many to be one of the best ways to share data (e.g., (Schofield et al. 2009, Poisot et al. 2013), http://blog.datadryad.org/2011/10/05/why-does-dryad- use-cc0/). Several other licenses and waivers also accomplish these same goals http://opendefinition.org/ licenses/#Data. Having a clear and open license (or waiver) will increase the chance that other scientists will be comfortable using your data."

### Setting up your project directory

What folders should you have, what files should go where

@TODO find my notes on this

Noble, W. S. (2009) A Quick Guide to Organizing Computational Biology Projects (ed F. Lewitter). PLoS Comp Biol. 5, e1000424.

### File paths, relative vs. hard-coded

### RAW data
DATA MASTERFILE--- DO NOT EDIT OVER MISTAKES.... want the data as RAW as possible. WHY find refs on this.



Provide RAW and PRocessed forms of the data.
Explain the differences between them with metadata, and commented code.
SHARE the code that morphs the code from raw to processed for analysis.

"Often, the data used in scientific analyses are mod- ified in some way from the original form in which they were collected. Values are averaged, units are convert- ed, or indices are calculated from direct measurements or observations to address the focal research questions and to fix issues associated with the raw data. However, the best way to process data depends on the question being asked, and corrections for common data limit- ations often change as better approaches are developed. It can also be very difficult to combine data from mult- iple sources that have each been processed in different ways. Therefore, to make your data as useful as possible it is best to share the data in as raw a form as possible. That means providing your data in a form that is as close as possible to the field measurements and observ- ations from which your analysis started.
This is not to say that your data are best suited for analysis in the raw form, but providing it in the raw form gives data users the most flexibility."

### R scripts, vs. Rmarkdown documents

when should something go into a script, and when should it go into an RMarkdown document...
tricky topic, and a decision youll want to make depending on your own personal workflow.

My rules:

- R scripts for cleaning and tidying data, generating data files, or long analyses.
- RMarkdown files for exploratory data analyses, WHAT ELSE.
- generating or altering of files should happen NOT in RMarkdown docs.

- put as MUCH as you can in R. All changes should occurr here. NOT in excel.

### Setting up a new project


